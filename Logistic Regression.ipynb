{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic Regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"k1OWBGQe7tKR","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jL2L-EfL7v9h","colab_type":"code","colab":{}},"source":["class Logistic_Regression:\n","\n","      #  'train' method takes argument as Learning Rate(alpha), Regularisation Constant(lam), and No.of Iterations(n_iter).\n","      #  All of these values have been initialised by a default value, but can be changed when required.\n","      #  J_hist and noi(number of iterations) keeps track of cost along with iteration. \n","  \n","  def train(self,alpha = 0.09,lam = 0.01,n_iter = 3500):\n","      self.n_iter = n_iter\n","      self.alpha = alpha\n","      self.lam = lam\n","      self.J_hist = []\n","      self.noi = []\n","  \n","      # definition of sigmoid function.\n","  def sig(self,x):\n","      return 1/(1+np.exp(-1*x))\n","  \n","      # 'fit' takes X_train,y_train , k(no.of classes) as arguments, applies gradinet descent algorithm to fit our parameter theta and returns theta.\n","  \n","  def fit(self,X,y,k):\n","      self.k = k\n","      m = X.shape[0]\n","      n = X.shape[1]\n","      self.theta = np.zeros((self.k,n +1))\n","      \n","      # Normalization.\n","      X= self.normalize(X)\n","     \n","      y_k = np.zeros((m,self.k))\n","      \n","      # Converting y_k into one vs All type matrix.\n","      for i in  range(m):\n","          y_k[i,y[i]] = 1\n","      \n","      # Gradient Descent Algorithm\n","      for i in range(self.n_iter):\n","          theta1 = self.theta\n","          theta1[:,0:1] = np.zeros((self.k,1))\n","          z = X@(self.theta.T)\n","          h = self.sig(z)\n","          # Parameter Update\n","          self.theta = self.theta - (self.alpha/m)*( ((h-y_k).T@X) + self.lam*theta1 )\n","          # Cost Function Calculation\n","          cost = (-1*np.sum(y_k*np.log(h) + (1-y_k)*np.log(1-h))/(m)) + (np.sum(self.theta[:,1:]**2)*(self.lam)/(2*m))\n","          self.J_hist.append(cost)\n","          self.noi.append(i)\n","          if(i==0):\n","            print(\"Initial Cost:\",cost)\n","          if(i==self.n_iter-1):\n","            print(\"Final Cost:\",cost)\n","      return self\n","      \n","      # Predicting value of target feature using trained model.     \n","  def predict(self,X):\n","      X  = self.normalize(X)\n","      s = X@self.theta.T\n","      s = self.sig(s)\n","      y_pred = s.argmax(axis = 1)\n","      return y_pred\n","  \n","      # Calculates accuracy for our prediction with test example.\n","  def accuracy(self,y_test,y_pred):\n","      m = len(y_test)\n","      sum1 =0\n","      for i in range(m):\n","          if(y_test[i]==y_pred[i]):\n","              sum1+=1\n","      return (sum1/m)*100\n","  \n","      # Normalises X\n","  def normalize(self,X):\n","      m = X.shape[0]\n","      for i in range(X.shape[1]):\n","          X[:,i] = (X[:,i] - np.mean(X[:,i]))/(np.std(X[:,i]) + np.exp(-9))\n","      X = np.hstack((np.ones((m, 1)), X))\n","      return X\n","  \n","      # returns the parameter 'theta'\n","  def get_params(self):\n","      return self.theta\n","           \n","      # splits the dataset into trainig set and test set based on input split fraction\n","  def test_train_split(self,X,y,size):\n","      m_test = int(X.shape[0]*size)\n","      X_test = X[0:m_test,:]\n","      y_test = y[0:m_test]\n","      X_train = X[m_test:,:]\n","      y_train = y[m_test:]\n","      return X_train,X_test,y_train,y_test   \n","  \n","      # plots the learning curve; cost function vs no.of iterations.\n","  def plot_learn(self):\n","      plt.plot(self.noi,self.J_hist)\n","      plt.xlabel(\"Number Of Iterations\")\n","      plt.ylabel(\"Cost Function\")\n","      plt.title(\"Const Function vs Iteration\")\n","\n","      \n","\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yo9KN1cK7170","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}