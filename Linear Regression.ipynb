{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Linear Regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"zRwcylJr7NLk","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUURbSkU7SXx","colab_type":"code","colab":{}},"source":["class Linear_Regression:\n","   \n","   #  'train' method takes argument as Learning Rate(alpha), Regularisation Constant(lam), and No.of Iterations(n_iter).\n","   #  All of these values have been initialised by a default value, but can be changed when required.\n","   #  J_hist and noi(number of iterations) keeps track of cost along with iteration. \n","     \n","  def train(self,alpha=0.05,lam=0.01,n_iter=6000):\n","    self.alpha = alpha\n","    self.n_iter = n_iter\n","    self.lam = lam \n","    self.J_hist = []\n","    self.noi = []\n","   \n","  #  'cost' method takes no arguments and returns the mean squared error of our hypothesis.\n","  \n","  def cost(self):\n","    h = self.X@self.theta\n","    return (1/(2*self.m))*np.sum((h-self.y)**2) + (self.lam/(self.m*2))*np.sum(self.theta[1:,0]**2)\n","  \n","  #  'fit' takes X_train,y_train as arguments, applies gradient descent algorithm to fit our parameters theta and returns theta.\n","  \n","  def fit(self,X,y):\n","    self.m = X.shape[0]\n","    self.n = X.shape[1]\n","    self.theta = np.zeros((self.n + 1,1))\n","    \n","    #  Normalization\n","    self.X = self.normalize(X)\n","    self.y = y[:,np.newaxis]\n","\n","    # Gradient Descent Algorithm.\n","    for i in range(self.n_iter):\n","         # Parameter update\n","         theta1  = self.theta\n","         theta1[0,0] = 0\n","         self.theta = self.theta - (self.alpha/self.m) * ((self.X.T @ (self.X @ self.theta - self.y)) + self.lam*theta1)\n","         self.J_hist.append(self.cost())\n","         self.noi.append(i)\n","         if(i==0):\n","           print(\"Initial Cost:\",self.cost())\n","         if(i==self.n_iter-1):\n","           print(\"Final Cost:\",self.cost())  \n","  \n","  # 'score' takes X,y as arguement and returns the score of our prediction.\n","  def score(self,X,y):\n","    X = self.normalize(X)\n","    y = y[:,np.newaxis]\n","    y_pre = X@self.theta\n","    return  1 - (((y - y_pre)**2).sum() / ((y - y.mean())**2).sum())\n","  \n","  # Calculates accuracy for our prediction with test example.\n","  def accuracy(self,y_test,y_pred):\n","    m = len(y_test)\n","    sum1 =0\n","    for i in range(m):\n","     if(y_test[i]==y_pred[i]):\n","      sum1+=1\n","    return (sum1/m)*100  \n","    \n","  # plots the learning curve; cost function vs no.of iterations.\n","  def plot_learn(self):\n","    plt.plot(self.noi,self.J_hist)\n","    plt.xlabel(\"Number Of Iterations\")\n","    plt.ylabel(\"Cost Function\")\n","    plt.title(\"Const Function vs Iteration\")\n","\n","  # splits the dataset into training set and test set based on the input split fraction.\n","  def test_train_split(self,X,y,size):\n","        m_test = int(X.shape[0]*size)\n","        X_test = X[0:m_test,:]\n","        y_test = y[0:m_test]\n","        X_train = X[m_test:,:]\n","        y_train = y[m_test:]\n","        return X_train,X_test,y_train,y_test   \n"," \n","  # predicting value of target feature using the trained model.\n","  def predict(self,X):\n","    m = X.shape[0]\n","    X = self.normalize(X)\n","    y_pred = X@self.theta\n","    return y_pred.flatten()\n","\n","  # Normalises X\n","  def normalize(self,X):\n","    m = X.shape[0]\n","    for i in range(X.shape[1]):\n","        X[:,i] = (X[:,i] - np.mean(X[:,i]))/(np.std(X[:,i]) + np.exp(-9))\n","    X = np.hstack((np.ones((m, 1)), X))\n","    return X\n","\n","  #  returns the parameter theta(weight) of the model.\n","  def get_params(self):\n","      return self.theta  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5IFrLwzU7aro","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}